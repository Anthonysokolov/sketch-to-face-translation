{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation using Frechet Inception Distance and pixelwise similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will evaluate the results of our different GANs using Frechet Inception Distance (FID score). The FID score compares the activations of real images in a trained network versus the activations of generated images. A lower score represents higher quality of generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook consults code from `https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directory paths for model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file, real=False):\n",
    "    '''\n",
    "    load in a jpeg file containing both the input image and the target imaage\n",
    "    '''\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # our test targets are stored as input/target pairs\n",
    "    if real:\n",
    "        w = image.shape[1] // 2\n",
    "        image = image[:,:w,:]\n",
    "\n",
    "    # normalize the pixel values\n",
    "    image = (image / 127.5) - 1 \n",
    "\n",
    "    # resize to 299,299,3 for inception net\n",
    "    image = tf.image.resize(image, [299, 299])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, real=False):\n",
    "    out = []\n",
    "    for img in glob.glob(path):\n",
    "        out.append(load(img, real))\n",
    "    return np.asarray(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = load_dataset('../data/sketch_data/test/*.jpg',real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['conditional_gan_256'] = load_dataset('./predictions/cgan*.jpg')\n",
    "results['cyclegan_256'] = load_dataset('./predictions/cyclegan*.jpg')\n",
    "results['resnet_scaled'] = load_dataset('./predictions/resnet128*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 299, 299, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['resnet_scaled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the paper \"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium\" the equation for FID score is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d^2 = ||mu_1 – mu_2||^2 + Tr(C_1 + C_2 – 2*sqrt(C_1*C_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre trained inception v3 network to be used for FID score\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def frechet_inception_distance(dist1, dist2):\n",
    "    '''\n",
    "    calculates the fid of two distributions\n",
    "    '''\n",
    "    # get final layer activations in inception net\n",
    "    activations1 = inception.predict(dist1)\n",
    "    activations2 = inception.predict(dist2)\n",
    "    \n",
    "    # get sum squared difference of average activationss\n",
    "    activation_diff = (activations1.mean(axis = 0) - activations2.mean(axis = 0)) ** 2\n",
    "    activation_diff = np.sum(activation_diff)\n",
    "    \n",
    "    # get covariances of activation layers\n",
    "    covariance1 = np.cov(activations1,rowvar=False)\n",
    "    covariance2 = np.cov(activations2,rowvar=False)\n",
    "    \n",
    "    covariance_term = covariance1 + covariance2 - 2*sqrtm(covariance1.dot(covariance2))\n",
    "    # get sum along diagonals\n",
    "    covariance_term = np.trace(covariance_term)\n",
    "    \n",
    "    return activation_diff + covariance_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_similarity(dist1,dist2):\n",
    "    '''\n",
    "    computes  average difference between pixel values of two distributions\n",
    "    '''\n",
    "    return abs(dist1.mean(axis=0)-dist2.mean(axis=0)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will calculate the FID score between all of our generated distributions and the 500 original test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel similarity for conditional_gan_256 : 0.90040755\n",
      "FID score for conditional_gan_256 : (142.43949031085748-1.7850260437925806e-06j)\n",
      "************\n",
      "Pixel similarity for cyclegan_256 : 0.9593999\n",
      "FID score for cyclegan_256 : (143.1787594240364-1.1949177051162446e-06j)\n",
      "************\n",
      "Pixel similarity for resnet_scaled : 0.90431577\n",
      "FID score for resnet_scaled : (153.3962406367699-1.4728668388100988e-06j)\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "for name, generated_images in results.items():\n",
    "    scores = {}\n",
    "    scores['pixel_similarity'] = pixel_similarity(real_images,generated_images)\n",
    "    scores['FID'] = frechet_inception_distance(real_images, generated_images)\n",
    "    metrics[name] = scores\n",
    "    print(\"Pixel similarity for\",name,':',scores['pixel_similarity'])\n",
    "    print(\"FID score for\",name,\":\",scores['FID'])\n",
    "    print(\"************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
